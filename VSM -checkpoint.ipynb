{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13eb62ab-86dc-4c7d-8931-9d39225f2edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "# Create the main application window\n",
    "root = tk.Tk()\n",
    "root.title(\"Simple Search App\")\n",
    "\n",
    "# Create and place widgets\n",
    "query_label = tk.Label(root, text=\"Enter your query:\")\n",
    "query_label.pack()\n",
    "\n",
    "query_entry = tk.Entry(root)\n",
    "query_entry.pack()\n",
    "\n",
    "result_label = tk.Label(root, text=\"\")\n",
    "result_label.pack()\n",
    "\n",
    "# Create Treeview widget\n",
    "tree = ttk.Treeview(root, columns=('Documents', 'Rank Value'), show='headings')\n",
    "tree.heading('Documents', text='Documents')\n",
    "tree.heading('Rank Value', text='Rank Value')\n",
    "tree.pack()\n",
    "\n",
    "\n",
    "# Initialize inverted index\n",
    "inverted_index = {}\n",
    "N = 20\n",
    "docs = [1,2,3,7,8,9,11,12,13,14,15,16,17,18,21,22,23,24,25,26]\n",
    "# Initialize stop words, single alpha characters, and target characters\n",
    "stop_words = {'a', 'is', 'the', 'of', 'all', 'and', 'to', 'can', 'be', 'as',\n",
    "              'once', 'for', 'at', 'am', 'are', 'has', 'have', 'had', 'up', 'his',\n",
    "              'her', 'in', 'on', 'no', 'we', 'do'}\n",
    "single_alpha = set('abcdefghijklmnopqrstuvwxyz')\n",
    "target_chars = ['%', '$', '*', \"'\", '’', '¨', '=', '+', '`', '/', '.', '·', ',', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '|', ':', '(', ')', '>', ';', '&', '“', '”', '[', ']', '@', '?', '}', '{']\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    for char in text:\n",
    "        if char in target_chars:\n",
    "            text = text.replace(char, ' ')\n",
    "        elif char == '-' or char == '_':\n",
    "            text = text.replace(char, '')\n",
    "        elif char == '\\n':\n",
    "            text = text.replace(char, ' ')\n",
    "    return text\n",
    "\n",
    "# Function to tokenize and stem text\n",
    "def tokenize_and_stem(text):\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    tokens = word_tokenize(text)\n",
    "    stemmed_tokens = [porter_stemmer.stem(token) for token in tokens if token.lower() not in stop_words and token not in single_alpha]\n",
    "    return stemmed_tokens\n",
    "\n",
    "# Function to calculate term frequency\n",
    "def calculate_term_frequency(tokens):\n",
    "    return dict(Counter(tokens))\n",
    "\n",
    "\n",
    "def cal_tf_idf_and_making_DataFrame():\n",
    "\n",
    "    directory = r'C:\\Users\\PC\\Desktop\\ResearchPapers\\ResearchPapers' \n",
    "    #initializing DataFrame\n",
    "    columns = [\"words\"]\n",
    "    columns_ = [filename.split('.')[0] for filename in sorted(os.listdir(directory), key=lambda x: int(x[:-4]))]\n",
    "    columns.extend(columns_)\n",
    "    df = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "    for filename in sorted(os.listdir(directory),key=lambda x: int(x[:-4]) ):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            # Preprocess text\n",
    "            with open(filepath, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                content = file.read()\n",
    "            print(f\"Preprocessed : {filepath}\")    \n",
    "            preprocessed_content = preprocess_text(content)\n",
    "    \n",
    "            # Tokenize and stem\n",
    "            print(f\"Tokenize and stem : {filepath}\") \n",
    "            stemmed_tokens = tokenize_and_stem(preprocessed_content)\n",
    "    \n",
    "            # Calculate term frequency\n",
    "            print(f\"Calculate term frequency : {filepath}\") \n",
    "            term_freq = calculate_term_frequency(stemmed_tokens)\n",
    "    \n",
    "    \n",
    "            for word , freq in term_freq.items():\n",
    "                if word not in df['words'].values:\n",
    "                    df = df._append({'words': word}, ignore_index=True)\n",
    "                    df.loc[df['words'] == word, filename.split('.')[0]] = freq\n",
    "                else:\n",
    "                    df.loc[df['words'] == word, filename.split('.')[0]] = freq\n",
    "    df = df.fillna(0)\n",
    "    # calculating df\n",
    "    df['df'] = (df.iloc[:, 1:22] != 0).sum(axis=1)\n",
    "    # calculating idf\n",
    "    df['idf'] = df['df'].apply(lambda x: math.log(N/x))\n",
    "    # calculating tf-idf\n",
    "    for doc in docs:\n",
    "        df['tf_idf' + str(doc)] = df[str(doc)] * df['idf']\n",
    "    # normalizing vectors \n",
    "    for doc in docs:\n",
    "        df['Normalized tf_idf' + str(doc)] = df['tf_idf' + str(doc)]/math.sqrt((df['tf_idf' + str(doc)] ** 2).sum())\n",
    "    print(df)\n",
    "    df.to_csv(r'C:\\Users\\PC\\Desktop\\ResearchPapers\\output.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#cal_tf_idf_and_making_DataFrame()\n",
    "\n",
    "\n",
    "def query_processing(query):\n",
    "    global tree  # Access the globally defined 'tree' variable\n",
    "    path = r'C:\\Users\\PC\\Desktop\\ResearchPapers\\output.csv'\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    pp_query = preprocess_text(query)\n",
    "    stem_query = tokenize_and_stem(pp_query)\n",
    "    term_freq = calculate_term_frequency(stem_query)\n",
    "\n",
    "    for word , freq in term_freq.items():\n",
    "        if word not in df['words'].values:   \n",
    "            df = df._append({'words': word}, ignore_index=True)\n",
    "            df.loc[df['words'] == word, filename.split('.')[0]] = freq\n",
    "        else:\n",
    "            df.loc[df['words'] == word, 'query'] = freq\n",
    "             \n",
    "    df = df.fillna(0)\n",
    "    df['tf_idf_query'] = df['query'] * df['idf']\n",
    "    # normalizing query\n",
    "    df['Normalized tf_idf_query' ] = df['tf_idf_query']/math.sqrt((df['tf_idf_query'] ** 2).sum())\n",
    "    #df.to_csv(r'C:\\Users\\PC\\Desktop\\ResearchPapers\\output.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "    rank = []\n",
    "    # ranking documents finding cosine similarity\n",
    "    for doc in docs:\n",
    "        rank.append(((df['Normalized tf_idf_query' ] * df['Normalized tf_idf' + str(doc)]).sum() , str(doc))) \n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "    rank = sorted(rank, key=lambda x: x[0], reverse=True)\n",
    "    for r , d in rank:\n",
    "        if r >= 0.025:\n",
    "            tree.insert('', 'end', values=(\"document-\" + str(d), r))\n",
    "    \n",
    "\n",
    "# Function to display the table upon search button click\n",
    "def show_table():\n",
    "    global tree  # Access the globally defined 'tree' variable\n",
    "    # Clear previous search results\n",
    "    for child in tree.get_children():\n",
    "        tree.delete(child)\n",
    "\n",
    "    # Get the query from the entry widget\n",
    "    query = query_entry.get()\n",
    "    query_processing(query)\n",
    "\n",
    "# Create search button\n",
    "search_button = tk.Button(root, text=\"Search\", command=show_table)\n",
    "search_button.pack()\n",
    "\n",
    "# Run the application\n",
    "root.mainloop()\n",
    "    \n",
    "\n",
    "\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126f234-82c4-46af-9031-046ea1e26705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2056df9e-6bef-4287-9cb9-81dc2be8c74f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
